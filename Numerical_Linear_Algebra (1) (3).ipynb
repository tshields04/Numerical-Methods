{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport matplotlib.pyplot as plt",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": "# Gaussian Elimination with Partial Pivoting",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Question 1\nWrite a function called `solve_system_gauss()` that takes in a matrix `A` and a vector `b` and solves the matrix equation $A\\bf{x} = \\bf{b}$ using Gaussian elimination (row reduction) with partial pivoting and back substitution. Outside of `solve_system_gauss()`, you should have the functions:\n* `reduce_row()`\n* `row_swap()`\n* `back_sub()`\n\nEach of these functions performs one part of solving the system of equations with Gaussian elimination",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Solution",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def Reduce_Row(A, row_index):\n    \n    for i in range(row_index+1,np.shape(A)[0]):                 # iterate over the rows of A below the current row\n        c = np.divide( A[i,row_index], A[row_index,row_index] ) # define a coefficient for Gaussian Elimnation\n        A[i,:] = A[i,:] - c*A[row_index,:]                      # use Gaussian Elimination to assign row values\n        \n    return",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "def Row_Swap(A, row_index):\n   \n    n = np.shape(A)[1]                                       # define the row length of A\n    temp = np.zeros(n)                                       # intialize a dummy row\n    current_column = np.array(A[row_index:,row_index])       # define the current column\n    max_row = A[row_index+np.argmax(abs(current_column)), :] # define the row with the maximum entry in the current column\n    current_row = A[row_index,:]                             # define the current row\n    temp[:] = current_row[:]                                 # assign the current row to temp\n    current_row[:] = max_row[:]                              # assign the max row to the current row\n    max_row[:] = temp[:]                                     # assign temp (current row) to the max row\n    \n    return",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": "def Back_Sub(U,b):\n    \n    x = np.zeros((np.shape(U)[0],1))                    # initialize vector\n    for row in range(np.shape(U)[0]-1,-1,-1):           # update x_row from the last row to the first row\n        x[row] = b[row]                                 # start with x_row = b_row\n        for column in range(row+1, np.shape(U)[1]):     # iterate over entries in row after x_row\n            x[row] = x[row] - U[row,column] * x[column] # subtract each entry other than x_row\n        x[row] /= U[row,row]                            # divide by coefficient of x_row\n        \n    return x    ",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": "def Solve_System_Gauss(A,b):\n    \n    aug = np.hstack( (A,b) )                          # augment A with b\n    for column in range(np.shape(A)[1]):              # iterate of the rows of A\n        Row_Swap(aug,column)                          # partial pivot\n        Reduce_Row(aug,column)                        # Gaussian Elimination\n    aug_mat, aug_b = np.hsplit(aug, [np.shape(A)[1]]) # extract the matrix part and the constant vector part from the augmented matrix\n    sol = Back_Sub(aug_mat,aug_b)                     # back-substitue the matrix and vector after row reduction\n    \n    return sol",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": "## Question 2\nUse `solve_system_gauss()` to solve the system of equations:\n\\begin{align*}\n 0 x_{1}+ -2 x_{2}+ 0 x_{3}+ 0 x_{4}+ 0 x_{5}&= 4 \\\\ \n -6 x_{1}+ 0 x_{2}+ 4 x_{3}+ 0 x_{4}+ 0 x_{5}&= -36 \\\\ \n 2 x_{1}+ 8 x_{2}+ 4 x_{3}+ 0 x_{4}+ -2 x_{5}&= -12 \\\\ \n -6 x_{1}+ -16 x_{2}+ -8 x_{3}+ -2 x_{4}+ 4 x_{5}&= 24 \\\\ \n -2 x_{1}+ -6 x_{2}+ 2 x_{3}+ 0 x_{4}+ 0 x_{5}&= -2\n\\end{align*}",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Solution",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "A = np.array([[ 0,-2., 0, 0, 0], \n              [-6,  0, 4, 0, 0], \n              [ 2,  8, 4, 0,-2], \n              [-6,-16,-8,-2, 4], \n              [-2, -6, 2, 0, 0]])\n\nb = np.array([[ 4.],\n              [-36], \n              [-12], \n              [ 24], \n              [ -2]])\n\nSolve_System_Gauss(A, b)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[ 4.],\n       [-2.],\n       [-3.],\n       [-4.],\n       [-4.]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": "# A theoretical and practical problem with Gaussian Elimination",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Question 1\nConsider the system of equations\n\\begin{align*}\n\\varepsilon x_1 + x_2 & = 1 \\\\\nx_1 + x_2 & = 2\n\\end{align*}\nFind a formula for both components of the solution $x_1$ and $x_2$ expressed in terms of $\\varepsilon$. What is the solution as $\\varepsilon \\to 0$?",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Solution",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The given system can be solved with an augmented matrix as follows:\n\n$ \\begin{bmatrix*}\n\\varepsilon & 1 &|& 1 \\\\\n1 & 1 &|& 2 \n\\end{bmatrix*}\n\\quad \\Rightarrow \\quad\n$\n$\nR_1 \\leftrightarrow R_2\n\\quad\n\\begin{bmatrix}\n1 & 1 &|& 2 \\\\\n\\varepsilon & 1 &|& 1\n\\end{bmatrix}\n\\quad \\Rightarrow \\quad\n$\n$\nR_2 \\rightarrow R_2 - \\varepsilon R_1\n\\quad\n\\begin{bmatrix}\n1 & 1 &|& 2 \\\\\n0 & 1-\\varepsilon &|& 1 - 2\\varepsilon\n\\end{bmatrix}\n\\quad\n\\Rightarrow\n\\quad\n$\n$\n\\begin{align}\nx_1 + x_2 &= 2 \\\\\n(1 - \\varepsilon)x_2 &= 1 - 2\\varepsilon\n\\end{align}\n\\quad\n\\Rightarrow\n\\quad\n$\n$\n\\begin{align}\nx_1 &= \\frac{(2 - 2\\varepsilon) - (1 - 2\\varepsilon)}{1 - \\varepsilon} = \\frac{1}{1 - \\varepsilon} \\\\\nx_2 &= \\frac{1 - 2\\varepsilon}{1 - \\varepsilon}\n\\end{align}\n$\n\n$$\n\\lim_{\\varepsilon\\to0} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}\n$$",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Question 2\nSolve the above system of equations WITHOUT partial pivoting, where $\\varepsilon = \\varepsilon_1 = 10^{-6}$. Solve the same system WITHOUT partial pivoting, where $\\varepsilon = \\varepsilon_2 = 10^{-16}$. Comment on the results. It may help to add an argument to `solve_system_gauss(...,pivot=True)`, where the input parameter `pivot` is a boolean whose default value is `True`, but a user (i.e., you) could instead specify `pivot=False` when calling `solve_system_gauss()`.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Solution\nLet's redefine `Solve_System_Gauss` to allow toggling of partial pivoting.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def Solve_System_Gauss(A,b, pivot=True):\n    \n    aug = np.hstack( (A,b) )                            # augment A with b\n    for row in range( np.shape(aug)[0] ):               # iterate over the rows of A\n        if pivot:                                       # check if partial pivoting will be used\n            Row_Swap( aug, row )                    # partial pivot the augment matrix in the current row\n        Reduce_Row( aug, row )                          # reduce the augmented matrix with Gaussian Elimination\n    aug_mat, aug_b = np.hsplit( aug, [np.shape(A)[0]] ) # seperate the augmented matrix back into a coefficient and constant matrix\n    sol = Back_Sub( aug_mat, aug_b )                    # define the system solution\n    \n    return sol",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": "Now let's plug in our system with $\\varepsilon = 10^{-6}$ and with $\\varepsilon = 10^{-16}$.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "e = 10**-6\ntest_A = np.array([[e, 1],\n                   [1, 1]])\n\ntest_b = np.array([[1],\n                   [2]])\n\nprint('Epsilon = 10**-6 :', Solve_System_Gauss(test_A,test_b,pivot=False))\n\ne = 10**-16\ntest_A = np.array([[e, 1],\n                   [1, 1]])\n\ntest_b = np.array([[1],\n                   [2]])\n\nprint('Epsilon = 10**-16 :', Solve_System_Gauss(test_A,test_b,pivot=False))",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Epsilon = 10**-6 : [[1.000001]\n [0.999999]]\nEpsilon = 10**-16 : [[2.22044605]\n [1.        ]]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": "When $\\varepsilon = 10^{-6}$, the solution is very close to the limit $\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$ but still off by $10^-6$.  When $\\varepsilon = 10^{-16}$ the solution component $x_2$ is fine, but the component $x_1$ is very far off. These errors occur because of a lack of partial pivotting which leads to catastrophic cancellation. The first pivot is VERY small compared to the rest of the matrix, so some error is introduced when $x_1$ is rounded to 1. This error is then multiplied by $10^{16}$ when $\\varepsilon$ is divided over.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Question 3\nSolve the same system WITH partial pivoting, again once each time for $\\varepsilon = \\varepsilon_1$ and $\\varepsilon = \\varepsilon_2$. Compare and explain your results with those obtained without partial pivoting.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Solution\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "e = 10**-6\ntest_A = np.array([[e, 1],\n                   [1, 1]])\n\ntest_b = np.array([[1],\n                   [2]])\n\nprint('Epsilon = 10**-6 :', Solve_System_Gauss(test_A,test_b,pivot=True))\n\ne = 10**-16\ntest_A = np.array([[e, 1],\n                   [1, 1]])\n\ntest_b = np.array([[1],\n                   [2]])\n\nprint('Epsilon = 10**-16 :', Solve_System_Gauss(test_A,test_b,pivot=True))",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Epsilon = 10**-6 : [[1.000001]\n [0.999999]]\nEpsilon = 10**-16 : [[1.]\n [1.]]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": "With partial pivoting, $|1| \\gg |\\varepsilon| $, so there is virtually no error that could introduce catastrophic cancellation.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Solving Systems with LU Decomposition",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Question 1\nWrite a function called `solve_system_LU()` that takes in a matrix `A` and a vector `b` to solve the equation $A\\mathbf{x} = \\mathbf{b}$. This function should call three functions:\n* `my_LU()`\n* `forward_sub()`\n* `back_sub()`\n\nEach of these functions performs one step required to solve $A\\mathbf{x} = \\mathbf{b}$ via an LU decomposition.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Solution",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def My_LU(A):\n\n    L = np.eye(np.shape(A)[0])                                           # initialize L as the identity matrix\n    U = np.array(A)                                                      # initialize U as input matrix\n    for column in range(np.shape(U)[1]):                                 # iterate over the columns of U \n        for row in range(column+1, np.shape(U)[0]):                      # iterate through the rows of the current column past the pivot\n            L[row,column] = np.divide( U[row,column], U[column,column] ) # update the corresponding entry of L\n        Reduce_Row(U,column)                                             # update the current column of U\n\n    return L, U\n    ",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": "def Forward_Sub(L,b):\n   \n    x = np.zeros((np.shape(L)[0]))                      # initialize solution vector\n    for row in range(np.shape(L)[0]):                   # update x_row from the first row to the last row\n        x[row] = b[row]                                 # start with x_row = b_row\n        for column in range(row):                       # iterate over entries in row before x_row\n            x[row] = x[row] - L[row,column] * x[column] # subtract each entry other than x_row\n        x[row] /= L[row,row]                            # divide by coefficient of x_row\n        \n    return x",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": "def Back_Sub(U,b):\n   \n    x = np.zeros((np.shape(U)[0]))                      # initialize solution vector\n    for row in range(np.shape(U)[0]-1,-1,-1):           # update x_row from the last row to the first row\n        x[row] = b[row]                                 # start with x_row = b_row\n        for column in range(row+1, np.shape(U)[1]):     # iterate over entries in row after x_row\n            x[row] = x[row] - U[row,column] * x[column] # subtract each entry other than x_row\n        x[row] /= U[row,row]                            # divide by coefficient of x_row\n    \n    return x    ",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": "def Solve_System_LU(A,b):\n    \n    L, U = My_LU(A)      # perform LU decomposition on A\n    y = Forward_Sub(L,b) # Ly = b\n    x = Back_Sub(U,y)    # Ux = y\n\n    return x",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "markdown",
      "source": "## Question 2\nSolve the system \n\\begin{align*}\nx_1 - 2x_2 - 4x_3 - 3x_4 & = 1 \\\\\n2x_1 -7x_2 - 7x_3 - 6x_4 & = 7 \\\\\n-x_1 + 2x_2 + 6x_3 + 4x_3& = 0 \\\\\n-4x_1 - x_2 + 9x_3 + 8x_4& = 3\n\\end{align*}\nusing `solve_system_LU()`",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Solution",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "test_A = np.array([[ 1.,-2,-4,-3],\n                   [ 2,-7,-7,-6],\n                   [-1, 2, 6, 4],\n                   [-4,-1, 9, 8]])\n\ntest_b = np.array([[1.],\n                   [7],\n                   [0],\n                   [3]])\n\nSolve_System_LU(test_A, test_b).reshape(np.shape(test_A)[0],1)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-11-aae961225af9>:5: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  x[row] = b[row]                                 # start with x_row = b_row\n",
          "output_type": "stream"
        },
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[-2.],\n       [-1.],\n       [ 2.],\n       [-3.]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "markdown",
      "source": "# Inverting a matrix using LU decomposition",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Question 1\nThe way you learned to invert a matrix $A\\in\\mathbb{R}^{n\\times n}$ in a first course in Linear Algebra is to row-reduce the augmented matrix\n\\begin{equation}\n[A \\ \\ \\vert \\ \\ I_n]\n\\end{equation}\nuntil the matrix $A$ was reduced to the identity matrix. The matrix that resulted from applying the row-reduction steps for $A$ to $I_n$ gave the inverse of $A$.\n\nWrite a Python function `my_inv_LU` that uses the $LU$ decomposition to invert a matrix A. When grading the problem, I will carefully consider the *efficiency* of your inversion routine.\n\nOf note, many linear algebra softwares invert a matrix via LU decomposition with pivoting (we haven't done pivoting in the $LU$ decomposition, but the point remains)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Solution",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def My_Inv_LU(A):\n\n    I = np.eye(np.shape(A)[0])                           # define identity matrix\n    A_inv = np.zeros( (np.shape(A)[0], np.shape(A)[1]) ) # initialize inverse matrix\n    n = np.shape(A_inv)[1]                               # define number of columns of A\n    L, U = My_LU(A)                                      # perform LU decomposition ONCE on A\n    for col in range(n):                                 # iterate over the columns of A\n        y = Forward_Sub(L, I[:,col])                     # solve Ly = I[:, col]\n        A_inv[:,col] = Back_Sub(U, y)                    # solve UA_inv[:, col] = y\n        \n    return A_inv",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 15
    },
    {
      "cell_type": "markdown",
      "source": "## Question 2\nSolve the $4\\times 4$ system in the previous question by finding $A^{-1}$ with `my_inv_LU` and the built-in function `np.dot()`.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Solution",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "test_A = np.array([[ 1.,-2,-4,-3],\n                   [ 2,-7,-7,-6],\n                   [-1, 2, 6, 4],\n                   [-4,-1, 9, 8]])\n\ntest_b = np.array([[1.],\n                   [7],\n                   [0],\n                   [3]])\n\nA_inv = My_Inv_LU(test_A)\nprint(A_inv)\nprint(np.dot(A_inv, test_b))",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[[14.66666667 -2.66666667  5.66666667  0.66666667]\n [-1.66666667  0.16666667 -0.66666667 -0.16666667]\n [-7.          1.5        -2.         -0.5       ]\n [15.         -3.          5.          1.        ]]\n[[-2.]\n [-1.]\n [ 2.]\n [-3.]]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 16
    },
    {
      "cell_type": "markdown",
      "source": "# Jacobi iteration",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Question 1\nWrite a function `my_jacobi()` that solves the matrix equation $A\\mathbf{x} = \\mathbf{b}$ with Jacobi iteration.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Solution",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Ax = b\n# C[i,j] = - A[i,j] / A[i,i]\n# d[i] = b[i] / A[i,i]\n# Then x^{k+1} = Cx^{k} + d, and x^{0} = d is a good guess\n# Jacobi's method converges to solution x^{*} if A is row-diagonally dominant \ndef My_Jacobi(A,b,N):\n    \n    C = np.zeros( (np.shape(A)[0], np.shape(A)[1]) )\n    d = np.zeros(np.shape(A)[0])\n    for i in range(np.shape(A)[0]):\n        d[i] = np.divide( b[i], A[i,i] )\n        for j in range(np.shape(A)[1]):\n            if i!=j:\n                C[i,j] = -np.divide( A[i,j], A[i,i] )\n    x = np.zeros(np.shape(C)[1])\n    for n in range(N):\n        x = np.dot( C, x ) + d\n        \n    return x\n        ",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "source": "## Question 2\nConsider the system\n\\begin{align*}\n3x_1 - x_2 & = 4 \\\\\n-x_1 + 3x_2 - 1x_3 & = -6 \\\\\n-x_2 + 3x_3 - x_4 & = 9 \\\\\n-x_3 + 3x_4 & = -8\n\\end{align*}\nExplain why this system is row-diagonally-dominant. Explain why this matters for Jacobi iteration. Solve the above system using `my_jacobi()` with 5 iterations. The actual answer is $[1, -1, 2, -2]$. How close is your answer?",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Solution",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "A matrix is row-diagonally-dominant if $|A_{i,i}| > \\sum|A_{i,j}|$ where $j \\neq i$. The coefficient matrix of the given system is $\\begin{bmatrix} 3 & -1 & 0 & 0 \\\\ -1 & 3 & -1 & 0 \\\\ 0 & -1 & 3 & -1 \\\\ 0 & 0 & -1 & 3 \\end{bmatrix}$. In each row $|A_{i,i}| = 3$, and $\\sum|A{i,j}| \\leq 2$ as $|-1|+|-1| = 2$ and $|-1| = 1$. Since the corresponding coefficient matrix of the system is row-diagonally-dominant, the system is too.\n\nThis matters for Jacobi iteration because convergence to the true solution is guarunteed regardless of the initial guess for row-diagonally-dominant systems.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "test_A = np.array([[ 3,-1, 0, 0],\n                   [-1, 3,-1, 0],\n                   [ 0,-1, 3,-1],\n                   [ 0, 0,-1, 3]])\n\ntest_b = np.array([[ 4],\n                   [-6],\n                   [ 9],\n                   [-8]])\n\nMy_Jacobi(test_A, test_b, 5)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-17-3c73a640714e>:11: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  d[i] = np.divide( b[i], A[i,i] )\n",
          "output_type": "stream"
        },
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([ 1.04526749, -1.08641975,  2.07407407, -2.05349794])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "markdown",
      "source": "My answer is within 0.1 for each component, which is okay for only 5 iterations.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Question 3\nConsider the system\n\\begin{align*}\n2x_1 - x_2 & = 3 \\\\\n-x_1 + 2x_2 - 1x_3 & = -5 \\\\\n-x_2 + 2x_3 - x_4 & = 7 \\\\\n-x_3 + 2x_4 & = -6\n\\end{align*}\nExplain why this system is NOT row-diagonally-dominant. Peform 5 Jacobi iterations to solve this system. The actual answer is $[1,-1,2,-2]$. How close is your answer? Try again, but perform 30 iterations. How close is your answer?",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Solution",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "This system is not row-diagonally-dominant because the absolute values of diagonal entries are 2, and the sum of the absolute values of the other entries in rows 2 and 3 is 2. So the diagonal entries are not much larger than the rest of the row for rows 2 and 3. ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "test_A = np.array([[ 2,-1, 0, 0],\n                   [-1, 2,-1, 0],\n                   [ 0,-1, 2,-1],\n                   [ 0, 0,-1, 2]])\n\ntest_b = np.array([[ 3],\n                   [-5],\n                   [ 7],\n                   [-6]])\n\nMy_Jacobi(test_A, test_b, 5)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-17-3c73a640714e>:11: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  d[i] = np.divide( b[i], A[i,i] )\n",
          "output_type": "stream"
        },
        {
          "execution_count": 19,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([ 1.34375, -1.65625,  2.5625 , -2.40625])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 19
    },
    {
      "cell_type": "markdown",
      "source": "This answer is much further off than before. An acceptable estimate should be accurate to at least one significant figure and usually much more.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "My_Jacobi(test_A, test_b, 30)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-17-3c73a640714e>:11: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  d[i] = np.divide( b[i], A[i,i] )\n",
          "output_type": "stream"
        },
        {
          "execution_count": 20,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([ 0.99797129, -0.99719639,  1.99671748, -1.99826728])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 20
    },
    {
      "cell_type": "markdown",
      "source": "With 30 iterations then answer is much better, even better than the row-diagonally-dominant estimation but with 5 iterations which isn't too surprising.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Question 4\nWhat do you think Questions 2 and Questions 3 are trying to demonstrate?",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Answer\n\nQuestions 2 and 3 are trying to demonstrate the exact significance of row-diagonally-dominant matrices as they relate to Jacobi iteration. Convergence is guarunteed for these special matrices, but that doesn't necessarily mean that a non-special matrix won't converge. It may just converge slower than the special matrix.",
      "metadata": {}
    }
  ]
}